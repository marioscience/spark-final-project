...
// Compute Category, Mean, Variance by year of US Births
    val populationStatistics = population
        .map(line => (line._1, (line._2, 1)))
      .reduceByKey((a, b) => (a._1+b._1, a._2+b._2))
      //.reduce((a, b) => ("all", (a._2._1+b._2._1, a._2._2+b._2._2)))

//    val totalsByYear = population
//      .reduceByKey(_+_)
//      .sortByKey()

    populationStatistics.collect().map(line => {
      println(line)
      line
    })
    //println(populationStatistics)
...


...

    // Create 1000 samples with replacement for bootstrapping
    for ( n <- 0 to 1000) {
      val resampledData = formatData(bootstrapSample.sample(true, 1))
      resampledData.collect().map(a => {
        bootstrapSampleAggregate = bootstrapSampleAggregate :+ a
      })
      //println(n)
      //resampledData.collect()//.map(println)
    }

    bootstrapSampleAggregate.map(summariseStatistics).foreach()

    // Summarize results
    //bootstrappingSamples.collect()

    spark.stop()
...

...
  def formatData(dataset: RDD[(String, Int)]): RDD[(String, (Int, Int))] = {
    dataset.map(line => (line._1, (line._2, 1)))
      .reduceByKey((a, b) => (a._1 + b._1, a._2 + b._2))
  }

  def summariseStatisticsV(rawDataPoints: RDD[(String, Int)])(yearBirthsData: (String, (Int, Int))) = {
    // calc mean and variance
    // TODO: fix results to two decimal places
    val year = yearBirthsData._1
    val mean = yearBirthsData._2._1.toDouble / yearBirthsData._2._2 // u = total/count
    val getVariance = (x: Double) => Math.pow(x - mean, 2) / yearBirthsData._2._2 // var(x) = E[(x-u)^2]
    // problem here is that each data point needs to be included in the variance equation for the sumatory.
    // Initially I incorrectly used the single aggregated total for the calculation.
    val variance = rawDataPoints.map(_._2.toDouble).map(getVariance).reduce(_+_)

    (year, mean, variance)
  }
...
